
# ================== # Dataset info # ================== #
Data source: kits - sketch
Sketching method: pminhash
Data Portion: 37
Sampling k: 1024
Using Counsketch: True
# ================== # Training info # ================== #
batch size: 5
alpha: 0.001
max_iter: 200
WAN_bandwidth: 10
mem_occupancy: 4
# ================== #   Info End   # ================== #

Iteration 0, batch sum loss: 0.7015543722814198 Time: 1.160872220993042s
Iteration 1, batch sum loss: 0.7002324719419026 Time: 1.163099765777588s
Iteration 2, batch sum loss: 0.6990525593458907 Time: 1.161163568496704s
Iteration 3, batch sum loss: 0.6979796498595372 Time: 1.1641807556152344s
Iteration 4, batch sum loss: 0.696994845241891 Time: 1.1732699871063232s
Iteration 5, batch sum loss: 0.6960847200035538 Time: 1.1575837135314941s
Iteration 6, batch sum loss: 0.6952392675790248 Time: 1.1556823253631592s
Iteration 7, batch sum loss: 0.6944506064562852 Time: 1.1581213474273682s
Iteration 8, batch sum loss: 0.6937125608400002 Time: 1.1680517196655273s
Iteration 9, batch sum loss: 0.6930199060028349 Time: 1.166473388671875s
Iteration 10, batch sum loss: 0.6923683054702925 Time: 1.2320537567138672s
Iteration 11, batch sum loss: 0.6917540579448165 Time: 1.4221994876861572s
Iteration 12, batch sum loss: 0.6911739294520838 Time: 1.2811388969421387s
Iteration 13, batch sum loss: 0.6906251012860657 Time: 1.1840455532073975s
Iteration 14, batch sum loss: 0.690105067343485 Time: 1.211759328842163s
Iteration 15, batch sum loss: 0.6896116185398417 Time: 1.7673923969268799s
Iteration 16, batch sum loss: 0.6891427499955051 Time: 1.835970401763916s
Iteration 17, batch sum loss: 0.6886966658336007 Time: 2.136442184448242s
Iteration 18, batch sum loss: 0.6882717557575374 Time: 2.0792033672332764s
Iteration 19, batch sum loss: 0.6878665380427693 Time: 2.1248695850372314s
Iteration 20, batch sum loss: 0.6874796529110753 Time: 2.109349012374878s
Iteration 21, batch sum loss: 0.6871098860358861 Time: 2.102370023727417s
Iteration 22, batch sum loss: 0.6867561113596836 Time: 2.179291248321533s
Iteration 23, batch sum loss: 0.6864173081070112 Time: 2.1513354778289795s
Iteration 24, batch sum loss: 0.6860925097110596 Time: 2.088655471801758s
Iteration 25, batch sum loss: 0.6857808588870712 Time: 1.1690471172332764s
Iteration 26, batch sum loss: 0.6854815700206545 Time: 1.1821374893188477s
Iteration 27, batch sum loss: 0.6851939251018847 Time: 1.171363115310669s
Iteration 28, batch sum loss: 0.6849171004610061 Time: 1.201392412185669s
Iteration 29, batch sum loss: 0.68465062175383 Time: 1.3648488521575928s
Iteration 30, batch sum loss: 0.6843937957716288 Time: 1.2249586582183838s
Iteration 31, batch sum loss: 0.6841461312368186 Time: 1.1715350151062012s
Iteration 32, batch sum loss: 0.6839071125101187 Time: 1.1540172100067139s
Iteration 33, batch sum loss: 0.6836762144561666 Time: 1.185234785079956s
Iteration 34, batch sum loss: 0.6834530360403905 Time: 1.1604244709014893s
Iteration 35, batch sum loss: 0.6832371758597549 Time: 1.1705193519592285s
Iteration 36, batch sum loss: 0.6830282798899303 Time: 1.1805675029754639s
Iteration 37, batch sum loss: 0.6828259427942166 Time: 1.1710004806518555s
Iteration 38, batch sum loss: 0.6826298809874742 Time: 1.1928825378417969s
Iteration 39, batch sum loss: 0.6824396174802698 Time: 1.1645479202270508s
Iteration 40, batch sum loss: 0.6822550640002778 Time: 1.225005865097046s
Iteration 41, batch sum loss: 0.6820758939628623 Time: 1.1769959926605225s
Iteration 42, batch sum loss: 0.6819018514148665 Time: 1.1935176849365234s
Iteration 43, batch sum loss: 0.6817326535801599 Time: 1.1870694160461426s
Iteration 44, batch sum loss: 0.681568047297127 Time: 1.211963176727295s
Iteration 45, batch sum loss: 0.681407879801248 Time: 1.221052885055542s
Iteration 46, batch sum loss: 0.6812519073907267 Time: 1.236644983291626s
Iteration 47, batch sum loss: 0.6811000120575054 Time: 1.1848139762878418s
Iteration 48, batch sum loss: 0.6809519078378706 Time: 1.2028236389160156s
Iteration 49, batch sum loss: 0.6808075390524451 Time: 1.1709473133087158s
Iteration 50, batch sum loss: 0.6806667221316498 Time: 1.1827762126922607s
Iteration 51, batch sum loss: 0.6805292493833425 Time: 1.1688268184661865s
Iteration 52, batch sum loss: 0.6803950133930142 Time: 1.151355504989624s
Iteration 53, batch sum loss: 0.6802639486459571 Time: 1.17268705368042s
Iteration 54, batch sum loss: 0.6801357931530349 Time: 1.1840190887451172s
Iteration 55, batch sum loss: 0.6800105305099033 Time: 1.1632776260375977s
Iteration 56, batch sum loss: 0.6798880367893011 Time: 1.2278523445129395s
Iteration 57, batch sum loss: 0.6797681820881698 Time: 1.1589953899383545s
Iteration 58, batch sum loss: 0.6796508799749996 Time: 1.187246561050415s
Iteration 59, batch sum loss: 0.6795359477560599 Time: 1.1894381046295166s
Iteration 60, batch sum loss: 0.6794233968334217 Time: 1.1706809997558594s
Iteration 61, batch sum loss: 0.6793132158007466 Time: 1.200951337814331s
Iteration 62, batch sum loss: 0.6792051644791997 Time: 1.170081615447998s
Iteration 63, batch sum loss: 0.6790990765661681 Time: 1.1920011043548584s
Iteration 64, batch sum loss: 0.6789952765784373 Time: 1.17750883102417s
Iteration 65, batch sum loss: 0.6788932383786416 Time: 1.1764888763427734s
Iteration 66, batch sum loss: 0.6787930990657736 Time: 1.1888175010681152s
Iteration 67, batch sum loss: 0.678694919295144 Time: 1.1935079097747803s
Iteration 68, batch sum loss: 0.6785984815635548 Time: 1.1751837730407715s
Iteration 69, batch sum loss: 0.6785037397116979 Time: 1.1688978672027588s
Iteration 70, batch sum loss: 0.6784106238485555 Time: 1.2162904739379883s
Iteration 71, batch sum loss: 0.6783191370155814 Time: 1.190389633178711s
Iteration 72, batch sum loss: 0.6782292690043127 Time: 1.1671428680419922s
Iteration 73, batch sum loss: 0.6781407728195659 Time: 1.199866771697998s
Iteration 74, batch sum loss: 0.6780537951243657 Time: 1.179211139678955s
Iteration 75, batch sum loss: 0.6779683126030559 Time: 1.1673612594604492s
Iteration 76, batch sum loss: 0.6778841226196083 Time: 1.2025253772735596s
Iteration 77, batch sum loss: 0.6778011870545757 Time: 1.1900866031646729s
Iteration 78, batch sum loss: 0.6777197099402041 Time: 1.1976959705352783s
Iteration 79, batch sum loss: 0.6776394052164042 Time: 1.1769967079162598s
Iteration 80, batch sum loss: 0.6775602972734841 Time: 1.1853337287902832s
Iteration 81, batch sum loss: 0.6774823364454003 Time: 1.1616311073303223s
Iteration 82, batch sum loss: 0.6774056458249831 Time: 1.1862895488739014s
Iteration 83, batch sum loss: 0.6773299646812992 Time: 1.1810226440429688s
Iteration 84, batch sum loss: 0.6772554836808594 Time: 1.1638920307159424s
Iteration 85, batch sum loss: 0.6771819519929883 Time: 1.2016663551330566s
Iteration 86, batch sum loss: 0.6771095115706 Time: 1.159715175628662s
Iteration 87, batch sum loss: 0.6770381165930747 Time: 1.185286283493042s
Iteration 88, batch sum loss: 0.6769677131145411 Time: 1.1841535568237305s
Iteration 89, batch sum loss: 0.6768981784602901 Time: 1.1883175373077393s
Iteration 90, batch sum loss: 0.6768295253600446 Time: 1.1731441020965576s
Iteration 91, batch sum loss: 0.6767619043117117 Time: 1.174757957458496s
Iteration 92, batch sum loss: 0.6766951757195193 Time: 1.180088996887207s
Iteration 93, batch sum loss: 0.6766293435028021 Time: 1.1608235836029053s
Iteration 94, batch sum loss: 0.676564215608278 Time: 1.189042329788208s
Iteration 95, batch sum loss: 0.6764999701763259 Time: 1.1827313899993896s
Iteration 96, batch sum loss: 0.6764365898468687 Time: 1.1833446025848389s
Iteration 97, batch sum loss: 0.6763740020460669 Time: 1.1747136116027832s
Iteration 98, batch sum loss: 0.6763121109408397 Time: 1.17918062210083s
Iteration 99, batch sum loss: 0.6762509420548889 Time: 1.1912713050842285s
Iteration 100, batch sum loss: 0.6761905950177132 Time: 1.1887333393096924s
Iteration 101, batch sum loss: 0.6761308889414943 Time: 1.3073735237121582s
Iteration 102, batch sum loss: 0.6760720834832019 Time: 1.3046021461486816s
Iteration 103, batch sum loss: 0.6760137082253224 Time: 1.3510968685150146s
Iteration 104, batch sum loss: 0.6759560615530652 Time: 1.265547275543213s
Iteration 105, batch sum loss: 0.6758992838308167 Time: 1.1916038990020752s
Iteration 106, batch sum loss: 0.6758427287360919 Time: 1.211606740951538s
Iteration 107, batch sum loss: 0.6757871278150281 Time: 1.1802632808685303s
Iteration 108, batch sum loss: 0.6757321502999434 Time: 1.1961486339569092s
Iteration 109, batch sum loss: 0.6756776279568464 Time: 1.2990541458129883s
Iteration 110, batch sum loss: 0.6756238054963392 Time: 1.2475559711456299s
Iteration 111, batch sum loss: 0.6755706202236262 Time: 1.2268249988555908s
Iteration 112, batch sum loss: 0.675517809655844 Time: 1.2037594318389893s
Iteration 113, batch sum loss: 0.6754657966166011 Time: 1.1862759590148926s
Iteration 114, batch sum loss: 0.6754140923244915 Time: 1.1563720703125s
Iteration 115, batch sum loss: 0.6753629462902141 Time: 1.1496813297271729s
Iteration 116, batch sum loss: 0.6753124290082808 Time: 1.4691119194030762s
Iteration 117, batch sum loss: 0.6752624234957773 Time: 1.2078361511230469s
Iteration 118, batch sum loss: 0.6752128881037985 Time: 1.167686939239502s
Iteration 119, batch sum loss: 0.6751640263707074 Time: 1.1829392910003662s
Iteration 120, batch sum loss: 0.6751154272619037 Time: 1.1782681941986084s
Iteration 121, batch sum loss: 0.6750672361135627 Time: 2.0687689781188965s
Iteration 122, batch sum loss: 0.6750197813250524 Time: 1.9843511581420898s
Iteration 123, batch sum loss: 0.674972633595679 Time: 2.10334849357605s
Iteration 124, batch sum loss: 0.674925983952497 Time: 2.133171558380127s
Iteration 125, batch sum loss: 0.6748799342079435 Time: 2.2121400833129883s
Iteration 126, batch sum loss: 0.6748340854693523 Time: 2.183579444885254s
Iteration 127, batch sum loss: 0.674788778064764 Time: 2.0875916481018066s
Iteration 128, batch sum loss: 0.6747437957037833 Time: 2.111760377883911s
Iteration 129, batch sum loss: 0.6746993223057536 Time: 2.1808738708496094s
Iteration 130, batch sum loss: 0.6746552076814967 Time: 2.1546273231506348s
Iteration 131, batch sum loss: 0.6746115234153451 Time: 1.9356889724731445s
Iteration 132, batch sum loss: 0.6745682408007478 Time: 1.1626687049865723s
Iteration 133, batch sum loss: 0.6745253511912215 Time: 1.1512296199798584s
Iteration 134, batch sum loss: 0.6744827105077182 Time: 1.4143040180206299s
Iteration 135, batch sum loss: 0.6744407435546744 Time: 1.1846847534179688s
Iteration 136, batch sum loss: 0.6743989228796011 Time: 1.1740269660949707s
Iteration 137, batch sum loss: 0.6743575978815004 Time: 1.1647019386291504s
Iteration 138, batch sum loss: 0.6743164378455748 Time: 1.184601068496704s
Iteration 139, batch sum loss: 0.6742758085334195 Time: 1.2535033226013184s
Iteration 140, batch sum loss: 0.6742355025363503 Time: 1.3634178638458252s
Iteration 141, batch sum loss: 0.6741955570243877 Time: 1.246934175491333s
Iteration 142, batch sum loss: 0.6741558075587191 Time: 1.2055020332336426s
Iteration 143, batch sum loss: 0.6741166451537353 Time: 1.2138605117797852s
Iteration 144, batch sum loss: 0.6740775522410742 Time: 1.1852176189422607s
Iteration 145, batch sum loss: 0.6740388190175668 Time: 1.219555139541626s
Iteration 146, batch sum loss: 0.6740003775306861 Time: 1.1892435550689697s
Iteration 147, batch sum loss: 0.6739625015918078 Time: 1.2158186435699463s
Iteration 148, batch sum loss: 0.6739247788058759 Time: 1.2036633491516113s
Iteration 149, batch sum loss: 0.6738873302554547 Time: 1.2068545818328857s
Iteration 150, batch sum loss: 0.6738500951692719 Time: 1.1719114780426025s
Iteration 151, batch sum loss: 0.6738131022503501 Time: 1.2053589820861816s
Iteration 152, batch sum loss: 0.6737767260585021 Time: 1.176095724105835s
Iteration 153, batch sum loss: 0.6737404484047987 Time: 1.408571481704712s
Iteration 154, batch sum loss: 0.6737044818672885 Time: 1.2702405452728271s
Iteration 155, batch sum loss: 0.673668931957181 Time: 1.181859016418457s
Iteration 156, batch sum loss: 0.673633365817384 Time: 1.1479413509368896s
Iteration 157, batch sum loss: 0.673598101786349 Time: 1.3022050857543945s
Iteration 158, batch sum loss: 0.6735632420511134 Time: 1.5966770648956299s
Iteration 159, batch sum loss: 0.6735286026330153 Time: 1.3102617263793945s
Iteration 160, batch sum loss: 0.6734941138111179 Time: 1.1886999607086182s
Iteration 161, batch sum loss: 0.6734600049621621 Time: 1.190476417541504s
Iteration 162, batch sum loss: 0.6734262770748514 Time: 1.1611745357513428s
Iteration 163, batch sum loss: 0.6733926159867303 Time: 1.1731939315795898s
Iteration 164, batch sum loss: 0.6733592432484041 Time: 1.1579132080078125s
Iteration 165, batch sum loss: 0.6733261444242248 Time: 1.1568107604980469s
Iteration 166, batch sum loss: 0.6732932872198427 Time: 1.154637336730957s
Iteration 167, batch sum loss: 0.673260493380582 Time: 1.161729097366333s
Iteration 168, batch sum loss: 0.6732282678144517 Time: 1.1367952823638916s
Iteration 169, batch sum loss: 0.6731960448078801 Time: 1.1647703647613525s
Iteration 170, batch sum loss: 0.673164066559433 Time: 1.1712639331817627s
Iteration 171, batch sum loss: 0.6731323373548358 Time: 1.1574337482452393s
Iteration 172, batch sum loss: 0.673100606921274 Time: 1.149083137512207s
Iteration 173, batch sum loss: 0.6730695613981181 Time: 1.1678500175476074s
Iteration 174, batch sum loss: 0.6730383784512196 Time: 1.1601340770721436s
Iteration 175, batch sum loss: 0.6730073774082759 Time: 1.1521449089050293s
Iteration 176, batch sum loss: 0.6729767943092906 Time: 1.1707072257995605s
Iteration 177, batch sum loss: 0.6729464914123438 Time: 1.148193120956421s
Iteration 178, batch sum loss: 0.6729162491298163 Time: 1.1601848602294922s
Iteration 179, batch sum loss: 0.6728859974703308 Time: 1.1362249851226807s
Iteration 180, batch sum loss: 0.6728562562817731 Time: 1.1713988780975342s
Iteration 181, batch sum loss: 0.6728266850167467 Time: 1.156006097793579s
Iteration 182, batch sum loss: 0.6727970397332516 Time: 1.1595053672790527s
Iteration 183, batch sum loss: 0.6727678762611631 Time: 1.1536293029785156s
Iteration 184, batch sum loss: 0.6727387721408825 Time: 1.1569840908050537s
Iteration 185, batch sum loss: 0.6727100421167623 Time: 1.244678258895874s
Iteration 186, batch sum loss: 0.6726812011356956 Time: 1.261237382888794s
Iteration 187, batch sum loss: 0.672652613329306 Time: 1.358586311340332s
Iteration 188, batch sum loss: 0.6726244441656021 Time: 1.2479069232940674s
Iteration 189, batch sum loss: 0.6725962391733488 Time: 1.1723976135253906s
Iteration 190, batch sum loss: 0.6725684025688471 Time: 1.1749491691589355s
Iteration 191, batch sum loss: 0.6725404181111138 Time: 1.1504101753234863s
Iteration 192, batch sum loss: 0.6725128137454827 Time: 1.167484998703003s
Iteration 193, batch sum loss: 0.6724854022220453 Time: 1.1589295864105225s
Iteration 194, batch sum loss: 0.6724581483499303 Time: 1.1516005992889404s
Iteration 195, batch sum loss: 0.6724309061128685 Time: 1.1545352935791016s
Iteration 196, batch sum loss: 0.6724040556061347 Time: 1.169142246246338s
Iteration 197, batch sum loss: 0.6723772026527546 Time: 1.1372318267822266s
Iteration 198, batch sum loss: 0.672350558884691 Time: 1.1738371849060059s
Iteration 199, batch sum loss: 0.6723241810313514 Time: 1.1523346900939941s


# ================== #  Test Model  # ================== #
score: 154
len(y): 300
Predict precision: 0.5133333333333333
SecureMLModel.train_time_account: 1087.9078369158276
Total time cost: 1355.5912475603589 s